{"ast":null,"code":"import _asyncToGenerator from \"D:/Project/github-teams/teams-app-new/node_modules/@babel/runtime/helpers/esm/asyncToGenerator.js\";\n// Copyright (c) Microsoft Corporation.\n// Licensed under the MIT License.\nimport { AbortError } from \"./abort-controller/AbortError.js\";\nimport { RestError } from \"./restError.js\";\nimport { createHttpHeaders } from \"./httpHeaders.js\";\nimport { isNodeReadableStream, isWebReadableStream } from \"./util/typeGuards.js\";\n/**\n * Checks if the body is a Blob or Blob-like\n */\nfunction isBlob(body) {\n  // File objects count as a type of Blob, so we want to use instanceof explicitly\n  return (typeof Blob === \"function\" || typeof Blob === \"object\") && body instanceof Blob;\n}\n/**\n * A HttpClient implementation that uses window.fetch to send HTTP requests.\n * @internal\n */\nclass FetchHttpClient {\n  /**\n   * Makes a request over an underlying transport layer and returns the response.\n   * @param request - The request to be made.\n   */\n  sendRequest(request) {\n    return _asyncToGenerator(function* () {\n      const url = new URL(request.url);\n      const isInsecure = url.protocol !== \"https:\";\n      if (isInsecure && !request.allowInsecureConnection) {\n        throw new Error(`Cannot connect to ${request.url} while allowInsecureConnection is false.`);\n      }\n      if (request.proxySettings) {\n        throw new Error(\"HTTP proxy is not supported in browser environment\");\n      }\n      try {\n        return yield makeRequest(request);\n      } catch (e) {\n        throw getError(e, request);\n      }\n    })();\n  }\n}\n/**\n * Sends a request\n */\nfunction makeRequest(_x) {\n  return _makeRequest.apply(this, arguments);\n}\n/**\n * Creates a pipeline response from a Fetch response;\n */\nfunction _makeRequest() {\n  _makeRequest = _asyncToGenerator(function* (request) {\n    const {\n      abortController,\n      abortControllerCleanup\n    } = setupAbortSignal(request);\n    try {\n      const headers = buildFetchHeaders(request.headers);\n      const {\n        streaming,\n        body: requestBody\n      } = buildRequestBody(request);\n      const requestInit = Object.assign(Object.assign({\n        body: requestBody,\n        method: request.method,\n        headers: headers,\n        signal: abortController.signal\n      }, \"credentials\" in Request.prototype ? {\n        credentials: request.withCredentials ? \"include\" : \"same-origin\"\n      } : {}), \"cache\" in Request.prototype ? {\n        cache: \"no-store\"\n      } : {});\n      // According to https://fetch.spec.whatwg.org/#fetch-method,\n      // init.duplex must be set when body is a ReadableStream object.\n      // currently \"half\" is the only valid value.\n      if (streaming) {\n        requestInit.duplex = \"half\";\n      }\n      /**\n       * Developers of the future:\n       * Do not set redirect: \"manual\" as part\n       * of request options.\n       * It will not work as you expect.\n       */\n      const response = yield fetch(request.url, Object.assign(Object.assign({}, requestInit), request.requestOverrides));\n      // If we're uploading a blob, we need to fire the progress event manually\n      if (isBlob(request.body) && request.onUploadProgress) {\n        request.onUploadProgress({\n          loadedBytes: request.body.size\n        });\n      }\n      return buildPipelineResponse(response, request, abortControllerCleanup);\n    } catch (e) {\n      abortControllerCleanup === null || abortControllerCleanup === void 0 ? void 0 : abortControllerCleanup();\n      throw e;\n    }\n  });\n  return _makeRequest.apply(this, arguments);\n}\nfunction buildPipelineResponse(_x2, _x3, _x4) {\n  return _buildPipelineResponse.apply(this, arguments);\n}\nfunction _buildPipelineResponse() {\n  _buildPipelineResponse = _asyncToGenerator(function* (httpResponse, request, abortControllerCleanup) {\n    var _a, _b;\n    const headers = buildPipelineHeaders(httpResponse);\n    const response = {\n      request,\n      headers,\n      status: httpResponse.status\n    };\n    const bodyStream = isWebReadableStream(httpResponse.body) ? buildBodyStream(httpResponse.body, {\n      onProgress: request.onDownloadProgress,\n      onEnd: abortControllerCleanup\n    }) : httpResponse.body;\n    if (\n    // Value of POSITIVE_INFINITY in streamResponseStatusCodes is considered as any status code\n    ((_a = request.streamResponseStatusCodes) === null || _a === void 0 ? void 0 : _a.has(Number.POSITIVE_INFINITY)) || ((_b = request.streamResponseStatusCodes) === null || _b === void 0 ? void 0 : _b.has(response.status))) {\n      if (request.enableBrowserStreams) {\n        response.browserStreamBody = bodyStream !== null && bodyStream !== void 0 ? bodyStream : undefined;\n      } else {\n        const responseStream = new Response(bodyStream);\n        response.blobBody = responseStream.blob();\n        abortControllerCleanup === null || abortControllerCleanup === void 0 ? void 0 : abortControllerCleanup();\n      }\n    } else {\n      const responseStream = new Response(bodyStream);\n      response.bodyAsText = yield responseStream.text();\n      abortControllerCleanup === null || abortControllerCleanup === void 0 ? void 0 : abortControllerCleanup();\n    }\n    return response;\n  });\n  return _buildPipelineResponse.apply(this, arguments);\n}\nfunction setupAbortSignal(request) {\n  const abortController = new AbortController();\n  // Cleanup function\n  let abortControllerCleanup;\n  /**\n   * Attach an abort listener to the request\n   */\n  let abortListener;\n  if (request.abortSignal) {\n    if (request.abortSignal.aborted) {\n      throw new AbortError(\"The operation was aborted. Request has already been canceled.\");\n    }\n    abortListener = event => {\n      if (event.type === \"abort\") {\n        abortController.abort();\n      }\n    };\n    request.abortSignal.addEventListener(\"abort\", abortListener);\n    abortControllerCleanup = () => {\n      var _a;\n      if (abortListener) {\n        (_a = request.abortSignal) === null || _a === void 0 ? void 0 : _a.removeEventListener(\"abort\", abortListener);\n      }\n    };\n  }\n  // If a timeout was passed, call the abort signal once the time elapses\n  if (request.timeout > 0) {\n    setTimeout(() => {\n      abortController.abort();\n    }, request.timeout);\n  }\n  return {\n    abortController,\n    abortControllerCleanup\n  };\n}\n/**\n * Gets the specific error\n */\n// eslint-disable-next-line @azure/azure-sdk/ts-use-interface-parameters\nfunction getError(e, request) {\n  var _a;\n  if (e && (e === null || e === void 0 ? void 0 : e.name) === \"AbortError\") {\n    return e;\n  } else {\n    return new RestError(`Error sending request: ${e.message}`, {\n      code: (_a = e === null || e === void 0 ? void 0 : e.code) !== null && _a !== void 0 ? _a : RestError.REQUEST_SEND_ERROR,\n      request\n    });\n  }\n}\n/**\n * Converts PipelineRequest headers to Fetch headers\n */\nfunction buildFetchHeaders(pipelineHeaders) {\n  const headers = new Headers();\n  for (const [name, value] of pipelineHeaders) {\n    headers.append(name, value);\n  }\n  return headers;\n}\nfunction buildPipelineHeaders(httpResponse) {\n  const responseHeaders = createHttpHeaders();\n  for (const [name, value] of httpResponse.headers) {\n    responseHeaders.set(name, value);\n  }\n  return responseHeaders;\n}\nfunction buildRequestBody(request) {\n  const body = typeof request.body === \"function\" ? request.body() : request.body;\n  if (isNodeReadableStream(body)) {\n    throw new Error(\"Node streams are not supported in browser environment.\");\n  }\n  return isWebReadableStream(body) ? {\n    streaming: true,\n    body: buildBodyStream(body, {\n      onProgress: request.onUploadProgress\n    })\n  } : {\n    streaming: false,\n    body\n  };\n}\n/**\n * Reads the request/response original stream and stream it through a new\n * ReadableStream, this is done to be able to report progress in a way that\n * all modern browsers support. TransformStreams would be an alternative,\n * however they are not yet supported by all browsers i.e Firefox\n */\nfunction buildBodyStream(readableStream, options = {}) {\n  let loadedBytes = 0;\n  const {\n    onProgress,\n    onEnd\n  } = options;\n  // If the current browser supports pipeThrough we use a TransformStream\n  // to report progress\n  if (isTransformStreamSupported(readableStream)) {\n    return readableStream.pipeThrough(new TransformStream({\n      transform(chunk, controller) {\n        if (chunk === null) {\n          controller.terminate();\n          return;\n        }\n        controller.enqueue(chunk);\n        loadedBytes += chunk.length;\n        if (onProgress) {\n          onProgress({\n            loadedBytes\n          });\n        }\n      },\n      flush() {\n        onEnd === null || onEnd === void 0 ? void 0 : onEnd();\n      }\n    }));\n  } else {\n    // If we can't use transform streams, wrap the original stream in a new readable stream\n    // and use pull to enqueue each chunk and report progress.\n    const reader = readableStream.getReader();\n    return new ReadableStream({\n      pull(controller) {\n        return _asyncToGenerator(function* () {\n          var _a;\n          const {\n            done,\n            value\n          } = yield reader.read();\n          // When no more data needs to be consumed, break the reading\n          if (done || !value) {\n            onEnd === null || onEnd === void 0 ? void 0 : onEnd();\n            // Close the stream\n            controller.close();\n            reader.releaseLock();\n            return;\n          }\n          loadedBytes += (_a = value === null || value === void 0 ? void 0 : value.length) !== null && _a !== void 0 ? _a : 0;\n          // Enqueue the next data chunk into our target stream\n          controller.enqueue(value);\n          if (onProgress) {\n            onProgress({\n              loadedBytes\n            });\n          }\n        })();\n      },\n      cancel(reason) {\n        onEnd === null || onEnd === void 0 ? void 0 : onEnd();\n        return reader.cancel(reason);\n      }\n    });\n  }\n}\n/**\n * Create a new HttpClient instance for the browser environment.\n * @internal\n */\nexport function createFetchHttpClient() {\n  return new FetchHttpClient();\n}\nfunction isTransformStreamSupported(readableStream) {\n  return readableStream.pipeThrough !== undefined && self.TransformStream !== undefined;\n}\n//# sourceMappingURL=fetchHttpClient.js.map","map":null,"metadata":{},"sourceType":"module","externalDependencies":[]}